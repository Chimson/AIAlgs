TODO:

Make Example its own class
Make the DecisionTree class hold some data attributes, which will
  remove a lot of the function arguments in
DecisionTree.Learner() need to return function T(e),
  where e is an example in the training set
  Need to make a Tree, maybe UnionFind or Linked list
Decide static vs non-static functions
Decide on public vs private members
Abstract the Condition Tree for conditions c(e) other than
  if the example has the condition/enum val then return true, otherwise
    return false
Example is Composition, maybe make it inherit a dictionary
OptionalNode and Node are a mess, need fixed
	maybe move the LNode and RNode to OptionalNode
Add a ToString() for Feature class
Feature class, for now, basically comes in 
	and helps retrieve the type string and Enum val values
	that Example uses in its Dictionary<string, Enum>
	Is this stupid?
Renove AddT and AddF functions in Node?
  maybe just make Node internal
ConditionTree keeps track of the examples it has already added by
	keeping a list of Examples, and checking them in Add()
ConditionTree Add either Adds a node to an empty tree or checks the example
	given and adds the cond node based on the example
	Its only this case that keeps track of the example that it has seen
Really study the example in the book, it tells you how find the 
  prediction for the target feature, and how the recursion works.

Example of T(e) Tree function

Features: Sex->{Male, Female}, Gender->{White, Black}, Name->{Bob, Finn, Barb}
Cs = {Male, White}
Target Feature Y = Name
y = 1
Es = [
  Male, White, Finn
  Male, Black, Bob 
  Female, Black, Barb
]

DTL(Cs={Male, White}, Y=Name, Es):
  c = Male
  te = [Male, White, Finn
        Male, Black, Bob  
  ]
  t1 = DTL(Cs={White}, Y=Name, te):
    c = White
    te = [
      Male, White, Finn  
    ]
    t1 = DTL({}, Name, te)
      c = None
      v = Finn
      T([Male, White, Finn]) = Finn
      return T
    fe = [
      Male, Black, Bob
    ]
    t0 = DTL({}, Name, fe):
      c = None
      T([Male, Black, Bob]) = Bob
      return T
    T([Male, White, Finn]) = if White then Finn else None
    T([Male, Black, Bob]) = if White then None else Bob
    return T

Tree example
Features: Sex->{Male, Female}, Gender->{White, Black}, Name->{Bob, Finn, Barb}
Cs = {Male, White}
Target Feature Y = Name
Examples = {[Male, White, Finn],    (This is a complete set)
						[Male, Black, Bob],
            [Female, Black, Barb],
						[Female, White, Mags]}
				    Male
			1/	         \0
     White         White  
    1/   \0      1/   \0
  Finn   Bob    Mags   Barb

# -----

Example in book





